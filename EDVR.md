# EDVR
# Abstract
视频恢复任务，包括超分辨率、去模糊等，越来越受到计算机视觉界的关注。一个名为
REDS基准测试在NTIRE19挑战赛中被释放。这个新的基准测试从两个方面挑战了现有的方法:
(1)给定大的运动，如何对齐多个帧
(2)如何有效的融合不同的帧与不同的运动和模糊。
在这项工作中，我们提出了一个新的视频的带有增强的可变形卷积的恢复框架，称为EDVR，以解决这些挑战。
首先，为了处理大的运动，我们设计了一个金字塔级联和可变形(PCD)对齐模块，其中帧的对齐是在特征层上使用可变形卷积从粗到细进行的。
其次，我们提出了一种时间和空间注意融合模块(TSA)，其中注意同时应用于时间和空间，以强调后续恢复的重要特征。
多亏了这些模块，我们的EDVR赢得了冠军，并在NTIRE19视频恢复和增强挑战的所有四个赛道上都远远超过第二名。EDVR还展示了在视频超分辨率和去模糊方面的优越性能。
# 1.Introduction
本文描述了我们的获胜方案。比赛发布了一个重要的“真实多场景数据集”，相比已有数据集，视频有更复杂的运动。
以前的研究只是扩展了图像重建，相邻帧间的时间冗余没有得到充分利用。最近的研究使用更复杂的pipeline解决上述问题，通常由四个组件组成，即特征提取、对齐、融合和重建。挑战在于当视频包含遮挡、大运动和严重模糊时，如何设计对齐和融合模块。为了获得高质量的输出，需要(1)在多个帧之间进行对齐并建立精确的对应关系，(2)有效地融合对齐后的特征进行重构。
## Alignment
大多数现有的方法都是通过显式地估计参考帧与其相邻帧之间的光流场来实现对齐。根据估计的运动场对相邻帧进行了翘曲。另一个研究方向是通过动态滤波[10]或可变形卷积实现隐式运动补偿[40]。REDS对现有的对齐算法提出了很大的挑战。特别是，对于基于流量的方法，精确的流量估计和准确的翘曲可能具有挑战性和时间消耗。在大运动的情况下，很难在单个分辨率范围内显式或隐式地执行运动补偿。
## Fusion
融合来自对齐帧s的特征是视频恢复任务中的另一个关键步骤。现有的大部分方法要么使用卷积对所有帧[2]进行早期融合，要么采用递归网络逐步融合多帧[32,6]。Liu等人提出了一种时间自适应网络，可以动态融合跨时间尺度。这些现有的方法都没有考虑到每个帧上潜在的视觉信息量——不同的帧和位置对重建的信息量和益处并不相同，因为一些帧或区域受到不完全对齐和模糊的影响。
## Our Solution
我们提出了一个统一的框架，称为EDVR，可扩展到各种视频恢复任务，包括超分辨率和去模糊。EDVR的核心是(1)一个称为金字塔的对齐模块，级联和可变形卷积(PCD)，以及(2)称为时间和空间注意的融合模块(TSA)。
PCD模块的灵感来自于TDAN[40]，它使用可变形的卷积在特征级别上将每个相邻帧对齐到参考帧。不同于TDAN，我们以从粗到细的方式进行对齐，以处理大而复杂的运动。具体来说，我们使用金字塔结构，首先将较低尺度的特征与粗估计进行对齐，然后将偏移量和对齐特征传播到较高尺度，以方便进行精确的运动补偿，类似于光流估计中采用的概念[7,9]。此外，我们在金字塔对齐操作后再级联一个额外的可变形卷积，以进一步提高对齐的鲁棒性。
所提出的TSA是一个融合模块，可以帮助跨多个对齐的特性聚合信息。为了更好地考虑每一帧上的视觉信息，我们通过计算参考帧的特征与相邻帧之间的元素相关性，引入时间注意。然后，相关系数在每个位置对每个相邻的特征进行加权，表明它对重建参考图像的信息量有多大。然后对所有帧的加权特征进行卷积和融合。在与时间注意融合后，我们进一步利用空间注意为每个信道中的每个位置分配权重，从而更有效地利用跨信道和空间信息。
我们参与了视频恢复和增强挑战中的所有四个赛道[29,28]，包括视频超分辨率(clean/blur)和视频去模糊(clean/compression)。由于有效的对齐和融合模块，我们的EDVR在所有四个具有挑战性的赛道上都获得了冠军，证明了我们方法的有效性和通用性。除了比赛结果，我们还报告了现有的视频超分辨率和去模糊基准的比较结果。
# 3. Methodology
## 3.1 Overview
一个参考帧，前后各N个邻帧，重建出高质量的参考帧。统一的通用视频重建架构，超分，去抹灰，去燥等等。
以VSR为例，2N+1个LR帧，每个邻帧通过PCD模块在特征级别与参考帧对齐。TSA模块融合不同帧的图像信息。PCD和TSA在3.2、3.3详细描述。融合后的特征通过重构模块，重构模块是残差块的级联，可以很容易地被其他SISR高级模块替换[46,52]。在网络的末端执行上采样操作以增加空间大小。最后，将预测的图像残差加到直接上采样的图像中，得到HR。（VSR直接PCD，TSA，重建，上采样）
对于其他具有高空间分辨率输入的任务，如视频去模糊，首先对输入帧进行带条纹卷积层的降采样。然后大部分的计算都在低分辨率的空间中进行，这在很大程度上节省了计算成本。最后的上采样层将把特征重新调整到原来的输入分辨率。一个PreDeblur模块用于对准模块前对模糊输入进行预处理，提高对准精度。
虽然单一的EDVR模型可以实现最先进的性能，但是我们采用了两阶段的策略来进一步提高NTIRE19的表现。具体来说，我们级联相同的EDVR网络，但深度较浅，以细化第一阶段的输出帧。级联网络可以进一步消除前一模型无法处理的严重运动模糊。详情见第3.4节。（去模糊这样级联OK，超分按之前思路两次2倍可尝试）
## 3.2 Alignment with Pyramid, Cascading and Deformable Convolution
我们首先简要回顾一下可变形卷积在对齐中的应用[40]，将每个相邻帧的特征与参考帧的特征对齐。不同于基于光流的方法，deformable alignment在每一帧的特征上应用，（一个公式很好理解）。我们使用调制的可变形模块[54]。
（这段全是公式，直接看论文）
PCD模块以这种由粗到精的方式将对齐精度提高到亚像素级。我们在第4.3节中演示了PCD的有效性。值得注意的是，PCD对齐模块是与整个框架共同学习的，没有额外的监督[40]或对其他任务如光流[48]的预训练。
## 3.3 Fusion with Temporal and Spatial Attention
帧间时间关系和帧内空间关系是融合的关键，因为1)由于遮挡、模糊区域和视差问题，不同的相邻帧信息不相同;2)前对齐阶段产生的失对齐和未对齐对后续重建效果产生不利影响。因此，在像素级对相邻帧进行动态聚合是实现有效融合的关键。为了解决上述问题，我们提出了TSA融合模块对每个帧分配像素级的聚合权值。具体来说，我们在融合过程中采用了时间和空间的注意，如图4所示。
时间注意的目标是中计算帧相似度，在嵌入空间。直观地说，在嵌入空间中，应该更多地关注与参考帧相似的相邻帧。
（又是一段公式，直接看）
然后根据融合特征计算出空间注意掩模。采用金字塔设计来增加注意力接受域。在此之后，融合的特征通过掩模的元素级乘法和加法进行调制，类似于[45]。有效性见第4.3节。
## 3.4 Two-Stage Restoration
虽然单个配备PCD对齐模块和TSA融合模块的EDVR可以实现最先进的性能，观察到恢复后的图像是不完美的，特别是当输入帧模糊或严重失真时。在这种恶劣的环境下，运动补偿和细节聚集受到影响，重建性能较差。
直观地说，粗略地恢复框架将大大减轻对齐和融合的压力。因此，我们采用了两阶段策略来进一步提高性能。具体来说，一个类似但较浅的EDVR网络被级联来改善第一阶段的输出帧。其优点有两方面:1)有效去除前一种模型无法处理的严重运动模糊，提高了复原质量;2)缓解了输出帧之间的不一致性。两阶段恢复的有效性见第4.4节。
（或许，超分两阶段，可去掉前一阶段的上采只加上残差，喂给第二阶段？）
# 4. Experiments
## 4.1 Training Datasets and Details
**Training datasets.** 
REDS有240训练视频，30验证，30测试（每个100帧）。他们选了4个作为测试，剩下266个训练。
Vimeo-90K[48]是一种应用广泛的训练数据集，通常与Vid4[21]和Vimeo-90K测试数据集一起使用(用Vimeo-90K-T表示)，当训练集的分布偏离测试集时，我们观察数据集偏差。更多详情请参阅4.3。
**Training details.** 
PCD对齐模块采用五个残差块(RB)进行特征提取。我们在重构模块中使用了40个RBs，在第二阶段模型中使用了20个RBs。每个残差块中的通道大小设置为128。
我们使用的RGB patches大小为64×64和256×256作为VSR和去模糊任务的输入。Mini-batch大小设置为32.网络需要连续五帧作为输入，除非另有规定。我们用随机水平翻转和90°旋转来增加训练数据。我们只采用Charbonnier罚函数[17]作为最终损失，ε设置为1e-3。
我们使用Adam optimizer训练模型，设置β1=0.9，β2=0.999。学习率初始化为4e-4。为了更快地收敛，我们用较浅网络的参数初始化较深的网络。我们使用PyTorch框架实现我们的模型，并使用Titan Xp对它们进行训练。
## 4.2. Comparisons with State-of-the-art Methods
**Video Super-Resolution.**
Vid4在VSR中比较常用，数据中运动有限，Visual artifacts？也存在于它的GT上。Vimeo-90K更大，更复杂。比较时基于这两个。
Vid4上DUF是27.33，EDVR27.35。Vimeo上RBPN是37.07，EDVR是37.61，都略领先。
## 4.3. Ablation Studies
**PCD Alignment Module.**
表4是成绩和计算量的比较。在图8中，我们展示了不同对齐模块前后的代表性特征，并描述了参考特征与相邻特征之间的flow(由PWCNet[35]导出)。与没有PCD对齐的流相比，PCD输出的flow要小得多、干净得多，说明PCD模块可以成功地处理大而复杂的运动。
**TSA Attention Module.**
表4展示了，相同的计算量，用TSA获得了额外0.14dB的表现。在图9中，我们给出了参考帧和相邻帧之间的flow和没帧的瞬时注意。可以看出，流量较小的帧和区域具有较高的关注度，说明运动越小，对应帧和区域的信息量越大。
# 5. Conclusion
我们已经介绍了我们在NTIRE2019中获胜的方法。为了应对本次比赛中发布的具有挑战性的基准测试，我们提出了EDVR，这是一个统一的框架，具有独特的设计，可以在各种视频恢复任务中实现良好的对齐和融合质量。由于PCD对齐模块和TSA融合模块，EDVR不仅在NTIRE2019挑战中赢得了所有四个轨道，而且在视频超分辨率和去模糊的几个基准测试中，EDVR表现出了优于现有方法的性能。